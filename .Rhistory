str(dataM3)
set.seed(1234)
inTrain <- createDataPartition(y=dataM3$classe,p=0.75, list=FALSE)
training1 <- dataM3[inTrain,]
testing1 <- dataM3[-inTrain,]
dim(training1)
## centering and scaling
preProcValues <- preProcess(dataM3[,-54], method = c("center", "scale"))
trainTransformed <- predict(preProcValues, training1[,-c(9:10)])
testTransformed <- predict(preProcValues, testing1[,-c(9:10)])
trainTransformed <- predict(preProcValues, training1[,-54])
testTransformed <- predict(preProcValues, testing1[,-54])
trainTransformedf <- cbind(trainTransformed,training1[,-54])
testTransformedf <-  cbind(testTransformed,testing1[,-54])
attach(trainTransformedf)
attach(testTransformedf)
##check for normality in data, multicollinearity, homoskedasticity,
# pairwise plot to analyse relationship
panel.hist <- function(x, ...)
{
usr <- par("usr"); on.exit(par(usr))
par(usr = c(usr[1:2], 0, 1.5) )
h <- hist(x, plot = FALSE)
breaks <- h$breaks; nB <- length(breaks)
y <- h$counts; y <- y/max(y)
rect(breaks[-nB], 0, breaks[-1], y, col = "cyan", ...)
}
panel.hist <- function(x, ...)
{
usr <- par("usr"); on.exit(par(usr))
par(usr = c(usr[1:2], 0, 1.5) )
h <- hist(x, plot = FALSE)
breaks <- h$breaks; nB <- length(breaks)
y <- h$counts; y <- y/max(y)
rect(breaks[-nB], 0, breaks[-1], y, col = "cyan", ...)
}
pairs(trainTransformedf, panel = panel.smooth,
cex = 1.5, pch = 20, bg = "light blue",
diag.panel = panel.hist, cex.labels = 1, font.labels = 2)
# association  between variables, non parametric method spearman rank
cor(trainTransformedf, use="complete.obs", method="spearman" )
corrgram(trainTransformedf, order=TRUE, lower.panel=panel.shade,
upper.panel=panel.pie, text.panel=panel.txt,cor.method="spearman",
main="Exploratory Displays for Correlation")
ptm <- proc.time()
library(caret)
library(kernlab)
library(plyr)
library(dplyr)
library(car)
library(MASS)
library(ggplot2)
library(corrgram)
library(MASS)
dataM1 <- read.csv("D:/Users/Kanu/Desktop/Analytics/Data Science Track/machine learning/pml-training.csv",stringsAsFactors=FALSE)
str(dataM1)
head(dataM1)
dim(dataM1)
attach(dataM1)
## data cleaning
remV1 <- as.matrix(apply(dataM1, 2, function(x) length(which(is.na(x)))))
remVn1 <- print(names(remV1[which(remV1[,1]==0),]))
myvars1 <- names(dataM1) %in% remVn1
dataM2 <- dataM1[,myvars]
summary(dataM2)
remV2 <- as.matrix(apply(dataM2, 2, function(x) length(which(x==""))))
remVn2 <- print(names(remV2[which(remV2[,1]==0),]))
myvars2 <- names(dataM2) %in% remVn2
dataM3 <- dataM2[,myvars2]
summary(dataM3)
dataM3 <- dataM3[,-c(1,2,3,4,5)]
## data partition for training and testing
set.seed(1234)
inTrain <- createDataPartition(y=dataM3$classe,p=0.75, list=FALSE)
training1 <- dataM3[inTrain,]
testing1 <- dataM3[-inTrain,]
dim(training1)
## centering and scaling
preProcValues <- preProcess(dataM3[,-54], method = c("center", "scale"))
trainTransformed <- predict(preProcValues, training1[,-54])
testTransformed <- predict(preProcValues, testing1[,-54])
trainTransformedf <- cbind(trainTransformed,training1[,-54])
testTransformedf <-  cbind(testTransformed,testing1[,-54])
set.seed(1234)
inTrain <- createDataPartition(y=dataM3$classe,p=0.75, list=FALSE)
dataM1 <- read.csv("D:/Users/Kanu/Desktop/Analytics/Data Science Track/machine learning/pml-training.csv",stringsAsFactors=FALSE)
str(dataM1)
head(dataM1)
dim(dataM1)
attach(dataM1)
## data cleaning
remV1 <- as.matrix(apply(dataM1, 2, function(x) length(which(is.na(x)))))
remVn1 <- print(names(remV1[which(remV1[,1]==0),]))
myvars1 <- names(dataM1) %in% remVn1
dataM2 <- dataM1[,myvars]
summary(dataM2)
## data cleaning
remV1 <- as.matrix(apply(dataM1, 2, function(x) length(which(is.na(x)))))
remVn1 <- print(names(remV1[which(remV1[,1]==0),]))
myvars1 <- names(dataM1) %in% remVn1
dataM2 <- dataM1[,myvars1]
summary(dataM2)
remV2 <- as.matrix(apply(dataM2, 2, function(x) length(which(x==""))))
remVn2 <- print(names(remV2[which(remV2[,1]==0),]))
myvars2 <- names(dataM2) %in% remVn2
dataM3 <- dataM2[,myvars2]
summary(dataM3)
dataM3 <- dataM3[,-c(1,2,3,4,5)]
## data partition for training and testing
set.seed(1234)
inTrain <- createDataPartition(y=dataM3$classe,p=0.75, list=FALSE)
training1 <- dataM3[inTrain,]
testing1 <- dataM3[-inTrain,]
dim(training1)
## centering and scaling
preProcValues <- preProcess(dataM3[,-54], method = c("center", "scale"))
trainTransformed <- predict(preProcValues, training1[,-54])
set.seed(1234)
inTrain <- createDataPartition(y=dataM3$classe,p=0.75, list=FALSE)
training1 <- dataM3[inTrain,]
testing1 <- dataM3[-inTrain,]
dim(training1)
## centering and scaling
str(dataM3)
dataM1 <- read.csv("D:/Users/Kanu/Desktop/Analytics/Data Science Track/machine learning/pml-training.csv",stringsAsFactors=FALSE)
str(dataM1)
head(dataM1)
dim(dataM1)
attach(dataM1)
## data cleaning
remV1 <- as.matrix(apply(dataM1, 2, function(x) length(which(is.na(x)))))
remVn1 <- print(names(remV1[which(remV1[,1]==0),]))
myvars1 <- names(dataM1) %in% remVn1
dataM2 <- dataM1[,myvars1]
summary(dataM2)
remV2 <- as.matrix(apply(dataM2, 2, function(x) length(which(x==""))))
remVn2 <- print(names(remV2[which(remV2[,1]==0),]))
myvars2 <- names(dataM2) %in% remVn2
dataM3 <- dataM2[,myvars2]
summary(dataM3)
str(dataM3)
summary(dataM3)
dataM3 <- dataM3[,-c(1,2,3,4,5,6)]
## data partition for training and testing
set.seed(1234)
inTrain <- createDataPartition(y=dataM3$classe,p=0.75, list=FALSE)
training1 <- dataM3[inTrain,]
testing1 <- dataM3[-inTrain,]
dim(training1)
## centering and scaling
preProcValues <- preProcess(dataM3[,-54], method = c("center", "scale"))
trainTransformed <- predict(preProcValues, training1[,-54])
testTransformed <- predict(preProcValues, testing1[,-54])
trainTransformedf <- cbind(trainTransformed,training1[,-54])
testTransformedf <-  cbind(testTransformed,testing1[,-54])
attach(trainTransformedf)
attach(testTransformedf)
##check for normality in data, multicollinearity, homoskedasticity,
# pairwise plot to analyse relationship
cor(trainTransformedf, use="complete.obs", method="spearman" )
set.seed(32323)
folds <-  createFolds(y=trainTransformedf$classe,k=10,list=TRUE,returnTrain=TRUE)
View(trainTransformed)
View(trainTransformedf)
library(caret)
library(plyr)
library(dplyr)
library(car)
library(corrgram)
library(kernlab)
library(ggplot2)
library(MASS)
dataM1 <- read.csv("D:/Users/Kanu/Desktop/Analytics/Data Science Track/machine learning/pml-training.csv",stringsAsFactors=FALSE)
str(dataM1)
attach(dataM1)
dim(dataM1)
library(MASS)
## data cleaning
head(dataM1)
remV1 <- as.matrix(apply(dataM1, 2, function(x) length(which(is.na(x)))))
remVn1 <- print(names(remV1[which(remV1[,1]==0),]))
myvars1 <- names(dataM1) %in% remVn1
dataM2 <- dataM1[,myvars1]
summary(dataM2)
remV2 <- as.matrix(apply(dataM2, 2, function(x) length(which(x==""))))
remVn2 <- print(names(remV2[which(remV2[,1]==0),]))
myvars2 <- names(dataM2) %in% remVn2
dataM3 <- dataM2[,myvars2]
summary(dataM3)
dataM3 <- dataM3[,-c(1,2,3,4,5,6)]
## data partition for training and testing
set.seed(1234)
inTrain <- createDataPartition(y=dataM3$classe,p=0.75, list=FALSE)
training1 <- dataM3[inTrain,]
testing1 <- dataM3[-inTrain,]
dim(training1)
## centering and scaling
preProcValues <- preProcess(dataM3[,-54], method = c("center", "scale"))
trainTransformed <- predict(preProcValues, training1[,-54])
testTransformed <- predict(preProcValues, testing1[,-54])
trainTransformedf <- cbind(trainTransformed,training1[,-54])
trainTransformedf <- cbind(trainTransformed,training1[,54])
testTransformedf <-  cbind(testTransformed,testing1[,54])
attach(trainTransformedf)
attach(testTransformedf)
cor(trainTransformedf, use="complete.obs", method="spearman" )
str(trainTransformedf)
trainTransformed <- predict(preProcValues, training$classe)
trainTransformed <- predict(preProcValues, training1$classe)
preProcValues <- preProcess(dataM3[,-54], method = c("center", "scale"))
trainTransformed <- predict(preProcValues, training1[,-54])
testTransformed <- predict(preProcValues, testing1[,-54])
trainTransformedf <- cbind(trainTransformed,training$classe)
trainTransformedf <- cbind(trainTransformed,training1$classe)
View(trainTransformedf)
trainTransformed <- predict(preProcValues, training1[,-54])
testTransformed <- predict(preProcValues, testing1[,-54])
detach(trainTransformedf)
detach(testTransformedf)
trainTransformed <- predict(preProcValues, training1[,-54])
testTransformed <- predict(preProcValues, testing1[,-54])
trainTransformedf <- cbind(trainTransformed,training1$classe)
testTransformedf <-  cbind(testTransformed,testing1$classe)
View(training1)
View(trainTransformed)
View(trainTransformedf)
View(dataM3)
cor(trainTransformedf, use="complete.obs", method="spearman" )
cor(trainTransformedf[,-54], use="complete.obs", method="spearman" )
set.seed(32323)
folds <-  createFolds(y=trainTransformedf$classe,k=10,list=TRUE,returnTrain=TRUE)
View(trainTransformedf)
View(testTransformedf)
View(testTransformedf)
folds <-  createFolds(y=trainTransformedf[,54],k=10,list=TRUE,returnTrain=TRUE)
fitControl <- trainControl(method = "repeatedcv", number = 10,repeats = 2)
# Stepwise Regression variable selection
fitStepH <- lm(Heat.Load ~ Rel.Compactness+Surf.Area+Wall.Area+Roof.Area+Height+Orient+Glaz.Area+Glaz.Area.Distribution,trainTransformedf)
fitStepH <- lm(trainTransformedf[,54] ~.,trainTransformedf)
stepH <- stepAIC(fitStepH, direction="both")
stepH$anova # display results
nnet <- train(classe ~.,trainTransformedf,
method = "nnet",tuneLength = 2,
trControl = fitControl,linout=TRUE,trace=FALSE)
nnet <- train(classe ~ .,trainTransformedf,
method = "nnet",tuneLength = 2,
trControl = fitControl,linout=TRUE,trace=FALSE)
# Second model:- knn
str(trainTransformedf)
nnet <- train(classe ~ .,trainTransformedf[,2:54],
method = "nnet",tuneLength = 2,
trControl = fitControl,linout=TRUE,trace=FALSE)
nrow(trainTransformedf$roll_belt)
trainTransformedf$roll_belt)
trainTransformedf$roll_belt
str(trainTransformedf)
str(trainTransformedf[,2])
nnet <- train(classe ~ .,trainTransformedf[,2:54],
method = "nnet",tuneLength = 2,
trControl = fitControl,linout=TRUE,trace=FALSE)
classe
str(classe)
str(training1)
nnet <- train(classe ~ .,data=trainTransformedf[,2:54],
method = "nnet",tuneLength = 2,
trControl = fitControl,linout=TRUE,trace=FALSE)
nnet <- train(trainTransformedf[,54] ~ .,data=trainTransformedf[,2:54],
method = "nnet",tuneLength = 2,
trControl = fitControl,linout=TRUE,trace=FALSE)
trainTransformedf1 <- trainTransformedf[,2:53]
testTransformedf1 <- testTransformedf[,2:53]
prednnetH <- predict(nnetH,testTransformedf1)
prednnetH <- predict(nnet,testTransformedf1)
nnet
testTransformedf1 <- testTransformedf[,2:54]
prednnetH <- predict(nnet,testTransformedf1)
testTransformedf1 <- testTransformedf[,2:53]
prednnetH <- predict(nnet,testTransformedf1[1:52])
View(testTransformedf1)
prednnetH <- predict(nnet,testTransformedf[,2:53])
training1$classe
View(testTransformedf)
prednnetH <- predict(nnet,testTransformedf[,2:54])
prednnetH <- predict(nnet,testTransformedf)
nnetH
nnet
prednnetH <- predict(nnet,testTransformedf[,-54])
svmH <- train(trainTransformedf[,54] ~ .,data=trainTransformedf[,2:54], method = "svmRadialCost", trControl = fitControl)
knnH <- train(trainTransformedf[,54] ~ .,data=trainTransformedf[,2:53],
method = "knn",
tuneLength = 2,
trControl = fitControl)
rfH <- train(trainTransformedf[,54] ~ .,data=trainTransformedf[,2:54],
method = "rf",importance=TRUE,
prox=TRUE,
trControl = fitControl)
ptm <- proc.time()
library(caret)
library(kernlab)
library(plyr)
library(dplyr)
library(car)
library(MASS)
library(ggplot2)
library(corrgram)
library(MASS)
dataM1 <- read.csv("D:/Users/Kanu/Desktop/Analytics/Data Science Track/machine learning/pml-training.csv",stringsAsFactors=FALSE)
str(dataM1)
head(dataM1)
dim(dataM1)
attach(dataM1)
## data cleaning
remV1 <- as.matrix(apply(dataM1, 2, function(x) length(which(is.na(x)))))
remVn1 <- print(names(remV1[which(remV1[,1]==0),]))
myvars1 <- names(dataM1) %in% remVn1
dataM2 <- dataM1[,myvars1]
summary(dataM2)
remV2 <- as.matrix(apply(dataM2, 2, function(x) length(which(x==""))))
remVn2 <- print(names(remV2[which(remV2[,1]==0),]))
myvars2 <- names(dataM2) %in% remVn2
dataM3 <- dataM2[,myvars2]
summary(dataM3)
dataM3 <- dataM3[,-c(1,2,3,4,5,6)]
## data partition for training and testing
set.seed(1234)
inTrain <- createDataPartition(y=dataM3$classe,p=0.75, list=FALSE)
training1 <- dataM3[inTrain,]
testing1 <- dataM3[-inTrain,]
dim(training1)
## centering and scaling
preProcValues <- preProcess(dataM3[,-54], method = c("center", "scale"))
trainTransformed <- predict(preProcValues, training1[,-54])
testTransformed <- predict(preProcValues, testing1[,-54])
trainTransformedf <- cbind(trainTransformed,training1$classe)
testTransformedf <-  cbind(testTransformed,testing1$classe)
##check for normality in data, multicollinearity, homoskedasticity,
# pairwise plot to analyse relationship
# panel.hist <- function(x, ...)
# {
#   usr <- par("usr"); on.exit(par(usr))
#   par(usr = c(usr[1:2], 0, 1.5) )
#   h <- hist(x, plot = FALSE)
#   breaks <- h$breaks; nB <- length(breaks)
#   y <- h$counts; y <- y/max(y)
#   rect(breaks[-nB], 0, breaks[-1], y, col = "cyan", ...)
# }
# pairs(trainTransformedf, panel = panel.smooth,
#       cex = 1.5, pch = 20, bg = "light blue",
#       diag.panel = panel.hist, cex.labels = 1, font.labels = 2)
#
#
# # association  between variables, non parametric method spearman rank
#
# cor(trainTransformedf[,-54], use="complete.obs", method="spearman" )
# corrgram(trainTransformedf, order=TRUE, lower.panel=panel.shade,
#          upper.panel=panel.pie, text.panel=panel.txt,cor.method="spearman",
#          main="Exploratory Displays for Correlation")
# cross validation, fitcontrol is for caret
set.seed(32323)
folds <-  createFolds(y=trainTransformedf[,54],k=10,list=TRUE,returnTrain=TRUE)
fitControl <- trainControl(method = "repeatedcv", number = 5,repeats = 2)
fitControl1 <- trainControl(method = "repeatedcv", number = 5,repeats = 1)
# First model neural networks
nnetH <- train(trainTransformedf[,54] ~ .,data=trainTransformedf[,2:54],
method = "nnet",tuneLength = 2,
trControl = fitControl,linout=FALSE,trace=FALSE)
ptm <- proc.time()
library(caret)
library(kernlab)
library(plyr)
library(dplyr)
library(car)
library(MASS)
library(ggplot2)
library(corrgram)
library(MASS)
dataM1 <- read.csv("D:/Users/Kanu/Desktop/Analytics/Data Science Track/machine learning/pml-training.csv",stringsAsFactors=FALSE)
str(dataM1)
head(dataM1)
dim(dataM1)
## data cleaning
remV1 <- as.matrix(apply(dataM1, 2, function(x) length(which(is.na(x)))))
remVn1 <- print(names(remV1[which(remV1[,1]==0),]))
myvars1 <- names(dataM1) %in% remVn1
dataM2 <- dataM1[,myvars1]
summary(dataM2)
remV2 <- as.matrix(apply(dataM2, 2, function(x) length(which(x==""))))
remVn2 <- print(names(remV2[which(remV2[,1]==0),]))
myvars2 <- names(dataM2) %in% remVn2
dataM3 <- dataM2[,myvars2]
summary(dataM3)
dataM3 <- dataM3[,-c(1,2,3,4,5,6)]
## data partition for training and testing
set.seed(1234)
inTrain <- createDataPartition(y=dataM3$classe,p=0.75, list=FALSE)
training1 <- dataM3[inTrain,]
testing1 <- dataM3[-inTrain,]
dim(training1)
## centering and scaling
preProcValues <- preProcess(dataM3[,-54], method = c("center", "scale"))
trainTransformed <- predict(preProcValues, training1[,-54])
testTransformed <- predict(preProcValues, testing1[,-54])
trainTransformedf <- cbind(trainTransformed,training1$classe)
testTransformedf <-  cbind(testTransformed,testing1$classe)
##check for normality in data, multicollinearity, homoskedasticity,
# pairwise plot to analyse relationship
# panel.hist <- function(x, ...)
# {
#   usr <- par("usr"); on.exit(par(usr))
#   par(usr = c(usr[1:2], 0, 1.5) )
#   h <- hist(x, plot = FALSE)
#   breaks <- h$breaks; nB <- length(breaks)
#   y <- h$counts; y <- y/max(y)
#   rect(breaks[-nB], 0, breaks[-1], y, col = "cyan", ...)
# }
# pairs(trainTransformedf, panel = panel.smooth,
#       cex = 1.5, pch = 20, bg = "light blue",
#       diag.panel = panel.hist, cex.labels = 1, font.labels = 2)
#
#
# # association  between variables, non parametric method spearman rank
#
# cor(trainTransformedf[,-54], use="complete.obs", method="spearman" )
# corrgram(trainTransformedf, order=TRUE, lower.panel=panel.shade,
#          upper.panel=panel.pie, text.panel=panel.txt,cor.method="spearman",
#          main="Exploratory Displays for Correlation")
# cross validation, fitcontrol is for caret
set.seed(32323)
folds <-  createFolds(y=trainTransformedf[,54],k=10,list=TRUE,returnTrain=TRUE)
fitControl <- trainControl(method = "repeatedcv", number = 5,repeats = 2)
fitControl1 <- trainControl(method = "repeatedcv", number = 5,repeats = 1)
# First model neural networks
nnetH <- train(trainTransformedf[,54] ~ .,data=trainTransformedf[,2:54],
method = "nnet",tuneLength = 2,
trControl = fitControl,linout=FALSE,trace=FALSE)
# Second model:- knn
knnH <- train(trainTransformedf[,54] ~ .,data=trainTransformedf[,2:53],
method = "knn",
tuneLength = 2,
trControl = fitControl)
# Third model :- Support Vector regression
svmH <- train(trainTransformedf[,54] ~ .,data=trainTransformedf[,2:54], method = "svmRadialCost", trControl = fitControl)
# Fourth model:- random forest
rfH <- train(trainTransformedf[,54] ~ .,data=trainTransformedf[,2:54],
method = "rf",importance=TRUE,
prox=TRUE,
trControl = fitControl1)
print(rfH)
plot(rfH)
dm <- as.matrix(varImp(rfH$finalModel))
barplot(dm[,1], main="Variable Importance in prediction",xlab="Variables",ylab="Importance Scale 0-100")
prednnetH <- predict(nnet,testTransformedf[,2:53])
predknnH <- predict(knnH,testTransformedf[,2:53])
predsvrH <- predict(svmH,testTransformedf[,2:53])
predrfH <- predict(rfH,testTransformedf[,2:53])
rfH
svmH <- train(trainTransformedf[,54] ~ .,data=trainTransformedf[,2:53], method = "svmRadialCost", trControl = fitControl)
save.image("D:/Users/Kanu/Desktop/Analytics/pml.RData")
library("bitops", lib.loc="~/R/win-library/3.1")
library("RCurl", lib.loc="~/R/win-library/3.1")
library("rmarkdown", lib.loc="~/R/win-library/3.1")
rstudio::diagnosticsReport()
library("bitops", lib.loc="~/R/win-library/3.1")
library("rmarkdown", lib.loc="~/R/win-library/3.1")
library("RCurl", lib.loc="~/R/win-library/3.1")
install packages("markdown")
library(markdown)
rpubsUpload(title, htmlFile, id = NULL, properties = list(), method = getOption("rpubs.upload.method", "internal"))
install packages("markdown")
library(markdown)
rpubsUpload(Energy Prediction Residential, index, id = NULL, properties = list(), method = getOption("rpubs.upload.method", "internal"))
install packages("markdown")
library(markdown)
rpubsUpload(epr, index, id = NULL, properties = list(), method = getOption("rpubs.upload.method", "internal"))
install packages("markdown")
library(markdown)
rpubsUpload(epr, index, id = NULL, properties = list(), method = getOption("rpubs.upload.method", "internal"))
install packages("markdown")
library(markdown)
rpubsUpload(index, htmlFile, id = NULL, properties = list(), method = getOption("rpubs.upload.method", "internal"))
install.packages("bitops")
install.packages("RCurl")
library("bitops", lib.loc="~/R/win-library/3.1")
library("RCurl", lib.loc="~/R/win-library/3.1")
library("rmarkdown", lib.loc="~/R/win-library/3.1")
setwd("D:/Users/Kanu/Desktop/Analytics/Data Science Track/DD/first_deck/Energy Prediction")
ublish(title = 'Energy Prediction Residential', 'index.html', host = 'rpubs')
publish(title = 'Energy Prediction Residential', 'index.html', host = 'rpubs')
publish(title = 'Energy Prediction Residential', 'index.html', host = 'rpubs')
publish(title = 'Energy Prediction Residential', 'index.html', host = 'rpubs')
rpubsUpload(title = 'Energy Prediction Residential', 'index.html', id = NULL, properties = list(), method = getOption("rpubs.upload.method", "internal"))
load('ep.RData',envir=.GlobalEnv)
rstudio::diagnosticsReport()
library(caret)
library(kernlab)
library(xlsx)
library(plyr)
library(dplyr)
library(car)
library(MASS)
library(ggplot2)
library(corrgram)
library(MASS)
library(gvlma)
library(randomForest)
library(corrplot)
library(reshape)
rstudio::diagnosticsReport()
library("Rcpp", lib.loc="~/R/win-library/3.1")
library("RCurl", lib.loc="~/R/win-library/3.1")
library("markdown", lib.loc="~/R/win-library/3.1")
library("rmarkdown", lib.loc="~/R/win-library/3.1")
